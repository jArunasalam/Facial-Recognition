{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aaron_Eckhart_0001.jpg', 'Aaron_Eckhart_0003.jpg', 'Abdullah_Gul_0001.jpg', 'Abdullah_Gul_0002.jpg', 'Abdullah_Gul_0003.jpg']\n",
      "Encoding Complete\n",
      "COUNTER: 1\n",
      "COUNTER: 2\n",
      "COUNTER: 3\n",
      "TOTAL: 1\n",
      "COUNTER: 1\n",
      "COUNTER: 2\n",
      "COUNTER: 3\n",
      "COUNTER: 4\n",
      "COUNTER: 5\n",
      "COUNTER: 6\n",
      "COUNTER: 7\n",
      "COUNTER: 8\n",
      "COUNTER: 9\n",
      "COUNTER: 10\n",
      "COUNTER: 11\n",
      "COUNTER: 12\n",
      "COUNTER: 13\n",
      "COUNTER: 14\n",
      "COUNTER: 15\n",
      "COUNTER: 16\n",
      "COUNTER: 17\n",
      "COUNTER: 18\n",
      "COUNTER: 19\n",
      "COUNTER: 20\n",
      "COUNTER: 21\n",
      "COUNTER: 22\n",
      "COUNTER: 23\n",
      "COUNTER: 24\n",
      "COUNTER: 25\n",
      "COUNTER: 26\n",
      "COUNTER: 27\n",
      "COUNTER: 28\n",
      "COUNTER: 29\n",
      "COUNTER: 30\n",
      "COUNTER: 31\n",
      "COUNTER: 32\n",
      "TOTAL: 2\n",
      "COUNTER: 33\n",
      "COUNTER: 34\n",
      "TOTAL: 3\n",
      "COUNTER: 35\n",
      "COUNTER: 36\n",
      "COUNTER: 37\n",
      "COUNTER: 38\n",
      "COUNTER: 39\n",
      "COUNTER: 40\n",
      "COUNTER: 41\n",
      "COUNTER: 42\n",
      "COUNTER: 43\n",
      "COUNTER: 44\n",
      "COUNTER: 45\n",
      "COUNTER: 46\n",
      "COUNTER: 47\n",
      "COUNTER: 48\n",
      "COUNTER: 49\n",
      "COUNTER: 50\n",
      "COUNTER: 51\n",
      "COUNTER: 52\n",
      "COUNTER: 53\n",
      "COUNTER: 54\n",
      "COUNTER: 55\n",
      "COUNTER: 56\n",
      "COUNTER: 57\n",
      "COUNTER: 58\n",
      "COUNTER: 59\n",
      "COUNTER: 60\n",
      "COUNTER: 61\n",
      "COUNTER: 62\n",
      "COUNTER: 63\n",
      "COUNTER: 64\n",
      "COUNTER: 65\n",
      "COUNTER: 66\n",
      "COUNTER: 67\n",
      "COUNTER: 68\n",
      "TOTAL: 4\n",
      "COUNTER: 1\n",
      "COUNTER: 2\n",
      "COUNTER: 3\n",
      "COUNTER: 4\n",
      "COUNTER: 5\n",
      "COUNTER: 6\n",
      "COUNTER: 7\n",
      "COUNTER: 8\n",
      "COUNTER: 9\n",
      "COUNTER: 10\n",
      "COUNTER: 11\n",
      "COUNTER: 12\n",
      "COUNTER: 13\n",
      "COUNTER: 14\n",
      "COUNTER: 15\n",
      "COUNTER: 16\n",
      "COUNTER: 17\n",
      "COUNTER: 18\n",
      "COUNTER: 19\n",
      "COUNTER: 20\n",
      "COUNTER: 21\n",
      "COUNTER: 22\n",
      "COUNTER: 23\n",
      "COUNTER: 24\n",
      "COUNTER: 25\n",
      "COUNTER: 26\n",
      "TOTAL: 5\n",
      "COUNTER: 27\n",
      "TOTAL: 6\n",
      "TOTAL: 7\n",
      "TOTAL: 8\n",
      "TOTAL: 9\n",
      "TOTAL: 10\n",
      "TOTAL: 11\n",
      "TOTAL: 12\n",
      "TOTAL: 13\n",
      "TOTAL: 14\n",
      "TOTAL: 15\n",
      "TOTAL: 16\n",
      "TOTAL: 17\n",
      "TOTAL: 18\n",
      "TOTAL: 19\n",
      "TOTAL: 20\n",
      "TOTAL: 21\n",
      "TOTAL: 22\n",
      "TOTAL: 23\n",
      "COUNTER: 28\n",
      "COUNTER: 29\n",
      "COUNTER: 30\n",
      "COUNTER: 31\n",
      "COUNTER: 32\n",
      "COUNTER: 33\n",
      "COUNTER: 34\n",
      "TOTAL: 24\n",
      "COUNTER: 35\n",
      "COUNTER: 36\n",
      "COUNTER: 37\n",
      "COUNTER: 38\n",
      "COUNTER: 39\n",
      "COUNTER: 40\n",
      "TOTAL: 25\n",
      "COUNTER: 41\n",
      "COUNTER: 42\n",
      "TOTAL: 26\n",
      "COUNTER: 43\n",
      "COUNTER: 44\n",
      "TOTAL: 27\n",
      "COUNTER: 1\n",
      "COUNTER: 2\n",
      "COUNTER: 3\n",
      "TOTAL: 28\n",
      "TOTAL: 29\n",
      "TOTAL: 30\n",
      "COUNTER: 4\n",
      "COUNTER: 5\n",
      "COUNTER: 6\n",
      "COUNTER: 7\n",
      "COUNTER: 8\n",
      "TOTAL: 31\n",
      "COUNTER: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "\n",
    "path = ((r\"C:\\Users\\ARUNASALAM\\Desktop\\SAMPLE_FACIAL_DATASET\"))\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "def markAttendance(name):\n",
    "    with open('Attendence.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')\n",
    "\n",
    "# p = our pre-treined model directory, on my case, it's on the same script's diretory.\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    " \n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    " \n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    " \n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "EYE_AR_THRESH = 0.3\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    " \n",
    "# initialize the frame counters and the total number of blinks\n",
    "COUNTER = 0\n",
    "TOTAL = 0\n",
    "test = None \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    #     img = captureScreen()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "    #eyes related.\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Get faces into webcam's image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # For each detected face, find the landmark.\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # Make the prediction and transfom it to numpy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        \n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        \n",
    "# threshold, and if so, increment the blink frame counter\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "            test = False #Mess with this variable to test eye detection********************************\n",
    "            print('COUNTER:', COUNTER)\n",
    "    # otherwise, the eye aspect ratio is not below the blink\n",
    "# threshold\n",
    "        else:\n",
    "                # if the eyes were closed for a sufficient number of\n",
    "                # then increment the total number of blinks\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES and test == False:\n",
    "                TOTAL += 1\n",
    "                print('TOTAL:', TOTAL)\n",
    "                test = True #Mess with this variable to test eye detection********************************\n",
    "                # reset the eye frame counter\n",
    "            #COUNTER = 0\n",
    "        \n",
    "            # Draw on our image, all the finded cordinate points (x,y) \n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(img, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        \n",
    "        # print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "        if faceDis[matchIndex] < 0.50 and test == True:    #50 is too low, raise this\n",
    "            name = classNames[matchIndex].upper()#RECOGNIZED IN SYSTEM: COLOR IS GREEN\n",
    "            #markAttendance(name)\n",
    "            #recognized face    \n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "           # print(name) --prints image name\n",
    "        \n",
    "        elif faceDis[matchIndex] > 0.50 and test == True:\n",
    "            name = 'Detecting'#not recognized in the system: LIVE HUMAN DETECTED (NOT RECOGNIZED IN SYSTEM)\n",
    "            #print('UNKNOWN HUMAN DETECTED') #--prints unknown face\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 255), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            COUNTER = 0\n",
    "            test == False #Mess with this variable to test eye detection********************************\n",
    "        else:\n",
    "            name = 'Unknown'#not recognized in the system: COLOR IS RED \n",
    "            #print(\"NOT IN THE SYSTEM\") #--prints unknown face and no detection of facial liveness\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 0, 255), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            test == False #Mess with this variable to test eye detection********************************\n",
    "        #recognized face    \n",
    "        #y1, x2, y2, x1 = faceLoc\n",
    "        #y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "        #cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        #cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "        #cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.imshow('FACIAL RECOGNITION',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Face recognition is less effective if facial expressions vary. A big smile can render the system less effective. For instance: Canada, in 2009, allowed only neutral facial expressions in passport photos(Wikipedia).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
